{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_3_gram.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/hKaGXxnRC9BsxLSjPBPK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauraAriasFdez/SentimentAnalysis/blob/main/project_3_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Connect to Google Drive\n"
      ],
      "metadata": {
        "id": "8VhWejcf1xxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN DIRECTORY STILL TO DO \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaL7Wx-N1yI_",
        "outputId": "2b59fbb8-8534-4e2a-d030-cd8dddfb072e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/gdrive/MyDrive/CSCI4511W/project/sentiments.csv\""
      ],
      "metadata": {
        "id": "d_i18n_q1z14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "cols = ['sentiment','id','date','query_string','user','text']\n",
        "sms_data = pd.read_csv(data_file, encoding='latin-1',header=None,names=cols)\n",
        "\n",
        "# replace lables 0 = neg  1= pos\n",
        "sms_data.sentiment = sms_data.sentiment.replace({0: 0, 4: 1})\n",
        "\n",
        "labels = sms_data[sms_data.columns[0]]"
      ],
      "metadata": {
        "id": "Ii-eEvWz12x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess Data"
      ],
      "metadata": {
        "id": "XxYGvMX116Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install texthero\n",
        "import texthero as hero"
      ],
      "metadata": {
        "id": "n6e0vbFw18DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "custom_cleaning = [\n",
        "  \n",
        "  #Replace not assigned values with empty space\n",
        "  hero.preprocessing.fillna,\n",
        "  hero.preprocessing.lowercase,\n",
        "  hero.preprocessing.remove_digits,\n",
        "  hero.preprocessing.remove_punctuation,\n",
        "  hero.preprocessing.remove_diacritics,\n",
        "  hero.preprocessing.remove_stopwords,\n",
        "  hero.preprocessing.remove_whitespace,\n",
        "  hero.preprocessing.stem\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "content = hero.clean(sms_data['text'], pipeline = custom_cleaning)"
      ],
      "metadata": {
        "id": "MlrCDSjP1-E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-NGRAM\n"
      ],
      "metadata": {
        "id": "dDz5Pr_o2Ang"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "count_vect = CountVectorizer(ngram_range=(3,3))\n",
        "n_gram_data = count_vect.fit_transform(content)\n",
        "\n",
        "n_gram_x_train,n_gram_x_test,y_train,y_test = train_test_split(n_gram_data,labels,test_size = 0.3, stratify=labels,random_state=100)"
      ],
      "metadata": {
        "id": "yCBaYRvZ2CjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "AvveD9852b5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"NAIVE BAYES + 3-GRAM______________________________________________________________\")\n",
        "clf_multinomialnb = MultinomialNB()\n",
        "clf_multinomialnb.fit(n_gram_x_train,y_train)\n",
        "\n",
        "y_pred = clf_multinomialnb.predict(n_gram_x_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "f1_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFO6t-G-2d6O",
        "outputId": "66dc800e-a3e6-42bf-f697-3bdadbd5c9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAIVE BAYES + 3-GRAM______________________________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.88      0.68    240000\n",
            "           1       0.72      0.31      0.44    240000\n",
            "\n",
            "    accuracy                           0.59    480000\n",
            "   macro avg       0.64      0.59      0.56    480000\n",
            "weighted avg       0.64      0.59      0.56    480000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4352261550022776"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear SVM"
      ],
      "metadata": {
        "id": "giWddnVq2nYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# SVM + TLF \n",
        "print(\"LINEAR SVM + 3 GRAM______________________________________________________________\")\n",
        "linearsvc = LinearSVC()\n",
        "linearsvc.fit(n_gram_x_train,y_train)\n",
        "\n",
        "y_pred = linearsvc.predict(n_gram_x_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "f1_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeMUxzo42mle",
        "outputId": "819cd45e-25fc-4a47-a331-4ae7113fc99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LINEAR SVM + 3 GRAM______________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.86      0.68    240000\n",
            "           1       0.69      0.32      0.44    240000\n",
            "\n",
            "    accuracy                           0.59    480000\n",
            "   macro avg       0.63      0.59      0.56    480000\n",
            "weighted avg       0.63      0.59      0.56    480000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4411319939511773"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression "
      ],
      "metadata": {
        "id": "frmpxAnU2uWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(\"LOGISTIC REGRESSION + 3 GRAMS______________________________________________________________\")\n",
        "\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(n_gram_x_train,y_train)\n",
        "\n",
        "y_pred = logisticRegr.predict(n_gram_x_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "f1_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGhN3G502x8b",
        "outputId": "28208baf-8229-410a-9711-ea69b83af3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOGISTIC REGRESSION + 3 GRAMS______________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.86      0.68    240000\n",
            "           1       0.70      0.33      0.45    240000\n",
            "\n",
            "    accuracy                           0.59    480000\n",
            "   macro avg       0.63      0.59      0.56    480000\n",
            "weighted avg       0.63      0.59      0.56    480000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44535248730331123"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}
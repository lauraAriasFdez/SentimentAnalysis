{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_bag_wrds.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_2ZoXUvkWnya",
        "0kA_EWzWXlci",
        "YaE2QQApb02Q",
        "r7uKmZVDb3Et"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMLO3elqYexX0A3ocPS8av+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauraAriasFdez/SentimentAnalysis/blob/main/project_bag_wrds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Connect to Google Drive\n"
      ],
      "metadata": {
        "id": "_2ZoXUvkWnya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN DIRECTORY STILL TO DO \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNxxyahZWr3g",
        "outputId": "97f2ebf8-8c6d-4a8c-9a3f-995bd23677f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/gdrive/MyDrive/CSCI4511W/project/sentiments.csv\""
      ],
      "metadata": {
        "id": "reMMbC5VWuMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "cols = ['sentiment','id','date','query_string','user','text']\n",
        "sms_data = pd.read_csv(data_file, encoding='latin-1',header=None,names=cols)\n",
        "\n",
        "# replace lables 0 = neg  1= pos\n",
        "sms_data.sentiment = sms_data.sentiment.replace({0: 0, 4: 1})\n",
        "\n",
        "labels = sms_data[sms_data.columns[0]].to_numpy()"
      ],
      "metadata": {
        "id": "nF3NxYdpWv0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f231ed6-26ae-4d87-b338-65b76af5d5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess Data"
      ],
      "metadata": {
        "id": "Y7ZDO251WyAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install texthero\n",
        "import texthero as hero"
      ],
      "metadata": {
        "id": "8E5uaJ6yW30a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c0aa61-a8eb-4215-b247-cf5056938dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed nltk-3.7 regex-2022.3.15 texthero-1.1.0 unidecode-1.3.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "custom_cleaning = [\n",
        "  \n",
        "  #Replace not assigned values with empty space\n",
        "  hero.preprocessing.fillna,\n",
        "  hero.preprocessing.lowercase,\n",
        "  hero.preprocessing.remove_digits,\n",
        "  hero.preprocessing.remove_punctuation,\n",
        "  hero.preprocessing.remove_diacritics,\n",
        "  hero.preprocessing.remove_stopwords,\n",
        "  hero.preprocessing.remove_whitespace,\n",
        "  hero.preprocessing.stem\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "content = hero.clean(sms_data['text'], pipeline = custom_cleaning)"
      ],
      "metadata": {
        "id": "SvHOWbv_W5w4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b8bebf-366b-4f8c-c993-e2ecb8569f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#content = content.to_numpy()"
      ],
      "metadata": {
        "id": "qO2G70n1W7MN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0908a50b-eace-4c46-ca79-c54947bd2d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words"
      ],
      "metadata": {
        "id": "0kA_EWzWXlci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "bag_words_data = count_vect.fit_transform(content)\n",
        "\n",
        "\n",
        "bag_wrds_x_train,bag_wrds_x_test,y_train,y_test = train_test_split(bag_words_data,labels,test_size = 0.3, stratify=labels,random_state=100)"
      ],
      "metadata": {
        "id": "i9tFSS5aXnN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "YaE2QQApb02Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# NAIVE BAYES + TLF \n",
        "print(\"NAIVE BAYES + BAG WRDS______________________________________________________________\")\n",
        "clf_multinomialnb = MultinomialNB()\n",
        "clf_multinomialnb.fit(bag_wrds_x_train,y_train)\n",
        "\n",
        "y_pred = clf_multinomialnb.predict(bag_wrds_x_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "f1_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MSyD-plbSxA",
        "outputId": "97f09756-4a01-4f6f-c7db-6e0a0965c0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAIVE BAYES + BAG WRDS______________________________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77    240000\n",
            "           1       0.78      0.73      0.76    240000\n",
            "\n",
            "    accuracy                           0.76    480000\n",
            "   macro avg       0.76      0.76      0.76    480000\n",
            "weighted avg       0.76      0.76      0.76    480000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7562095223774797"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LINEAR SVM"
      ],
      "metadata": {
        "id": "r7uKmZVDb3Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# SVM + TLF \n",
        "print(\"LINEAR SVM + BAG OF WRDS______________________________________________________________\")\n",
        "linearsvc = LinearSVC()\n",
        "linearsvc.fit(bag_wrds_x_train,y_train)\n",
        "\n",
        "y_pred = linearsvc.predict(bag_wrds_x_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "f1_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIQLs58abbqP",
        "outputId": "d4d6e8ab-c80e-4298-9da4-a1d82a1d088a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LINEAR SVM + BAG OF WRDS______________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.76      0.76    240000\n",
            "           1       0.76      0.77      0.77    240000\n",
            "\n",
            "    accuracy                           0.76    480000\n",
            "   macro avg       0.76      0.76      0.76    480000\n",
            "weighted avg       0.76      0.76      0.76    480000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.76522710844875"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "WPe48DoCb5l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(\"LOGISTIC REGRESSION + BAG OF WRDS______________________________________________________________\")\n",
        "\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(bag_wrds_x_train,y_train)\n",
        "\n",
        "y_pred = logisticRegr.predict(bag_wrds_x_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "f1_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvGr8-a-biXa",
        "outputId": "ba908d1e-3ba1-4be5-8f15-d4f873516722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOGISTIC REGRESSION + BAG OF WRDS______________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.75      0.77    240000\n",
            "           1       0.76      0.80      0.78    240000\n",
            "\n",
            "    accuracy                           0.77    480000\n",
            "   macro avg       0.77      0.77      0.77    480000\n",
            "weighted avg       0.77      0.77      0.77    480000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7791540773212855"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DFKERJH\n",
        "\n",
        "- compare RAM \n",
        "- compare CPU \n",
        "- compare f1-score\n",
        "\n",
        "\n",
        "if cpu and ram take a lot it may not be usefult to udate training as you receive a lot of tweets - ANALYSIS"
      ],
      "metadata": {
        "id": "d2KZRYqlcwAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/skabra5/Sentiment-Analysis-using-Bag-of-Words-TFIDF-Features-and-Recurrent-Neural-Net/blob/master/Sentiment_analysis.ipynb\n"
      ],
      "metadata": {
        "id": "44cZNYPmdWrN"
      }
    }
  ]
}